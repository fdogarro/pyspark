{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d2045dc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/opt/spark/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/04/23 13:42:46 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "22/04/23 13:42:47 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "/home/f_dev/.local/lib/python3.9/site-packages/pyspark/sql/context.py:77: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from pyspark import *\n",
    "from pyspark.sql import *\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "os.environ['PYSPARK_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = sys.executable\n",
    "os.environ['PYSPARK_SUBMIT_ARGS'] = \"\"\"--name job_name --master local --conf spark.dynamicAllocation.enabled=true pyspark-shell\"\"\"\n",
    "\n",
    "spark = SparkSession.builder.appName(\"DataFrame\").getOrCreate()\n",
    "conf = SparkConf().setMaster(\"local\").setAppName(\"Assignment 11\")\n",
    "sc = SparkContext.getOrCreate(conf=conf)\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86ae00f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "sales = spark.read.format(\"csv\")\\\n",
    ".option(\"header\", \"true\")\\\n",
    ".option(\"inferSchema\", \"true\")\\\n",
    ".load(\"retail-data/by-day/2011-10-04.csv\")\\\n",
    ".coalesce(5)\\\n",
    ".where(\"Description IS NOT NULL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b76231dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   569397|    23200|     JUMBO BAG PEARS|      10|2011-10-04 08:26:00|     2.08|   12747.0|United Kingdom|\n",
      "|   569397|    23201|  JUMBO BAG ALPHABET|      10|2011-10-04 08:26:00|     2.08|   12747.0|United Kingdom|\n",
      "|   569397|    23199|    JUMBO BAG APPLES|      10|2011-10-04 08:26:00|     2.08|   12747.0|United Kingdom|\n",
      "|   569397|   85099F|JUMBO BAG STRAWBERRY|      10|2011-10-04 08:26:00|     2.08|   12747.0|United Kingdom|\n",
      "|   569397|   85099B|JUMBO BAG RED RET...|      10|2011-10-04 08:26:00|     2.08|   12747.0|United Kingdom|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6a7e6627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+----------------------------+\n",
      "|Description            |DescOut                     |\n",
      "+-----------------------+----------------------------+\n",
      "|JUMBO BAG PEARS        |[jumbo, bag, pears]         |\n",
      "|JUMBO BAG ALPHABET     |[jumbo, bag, alphabet]      |\n",
      "|JUMBO BAG APPLES       |[jumbo, bag, apples]        |\n",
      "|JUMBO BAG STRAWBERRY   |[jumbo, bag, strawberry]    |\n",
      "|JUMBO BAG RED RETROSPOT|[jumbo, bag, red, retrospot]|\n",
      "+-----------------------+----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#tokenize string from Description column, splitting on a given character\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "tkn = Tokenizer().setInputCol(\"Description\").setOutputCol(\"DescOut\")\n",
    "tokenized = tkn.transform(sales.select(\"Description\"))\n",
    "tokenized.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55c3c22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', \"i'll\", \"you'll\", \"he'll\", \"she'll\", \"we'll\", \"they'll\", \"i'd\", \"you'd\", \"he'd\", \"she'd\", \"we'd\", \"they'd\", \"i'm\", \"you're\", \"he's\", \"she's\", \"it's\", \"we're\", \"they're\", \"i've\", \"we've\", \"you've\", \"they've\", \"isn't\", \"aren't\", \"wasn't\", \"weren't\", \"haven't\", \"hasn't\", \"hadn't\", \"don't\", \"doesn't\", \"didn't\", \"won't\", \"wouldn't\", \"shan't\", \"shouldn't\", \"mustn't\", \"can't\", \"couldn't\", 'cannot', 'could', \"here's\", \"how's\", \"let's\", 'ought', \"that's\", \"there's\", \"what's\", \"when's\", \"where's\", \"who's\", \"why's\", 'would']\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover\n",
    "englishStopWords = StopWordsRemover.loadDefaultStopWords(\"english\")\n",
    "print(englishStopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3b3b6715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+----------------------------+-------------------------------------+\n",
      "|Description            |DescOut                     |StopWordsRemover_d5f3719445d6__output|\n",
      "+-----------------------+----------------------------+-------------------------------------+\n",
      "|JUMBO BAG PEARS        |[jumbo, bag, pears]         |[jumbo, bag, pears]                  |\n",
      "|JUMBO BAG ALPHABET     |[jumbo, bag, alphabet]      |[jumbo, bag, alphabet]               |\n",
      "|JUMBO BAG APPLES       |[jumbo, bag, apples]        |[jumbo, bag, apples]                 |\n",
      "|JUMBO BAG STRAWBERRY   |[jumbo, bag, strawberry]    |[jumbo, bag, strawberry]             |\n",
      "|JUMBO BAG RED RETROSPOT|[jumbo, bag, red, retrospot]|[jumbo, bag, red, retrospot]         |\n",
      "+-----------------------+----------------------------+-------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover\n",
    "englishStopWords = StopWordsRemover.loadDefaultStopWords(\"english\")\n",
    "stops = StopWordsRemover()\\\n",
    ".setStopWords(englishStopWords)\\\n",
    ".setInputCol(\"DescOut\")\n",
    "stops.transform(tokenized).show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "039a97aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = stops.transform(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c29a8bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+---------+--------------------+\n",
      "|         Description|             DescOut|DescIndex| originalDescription|\n",
      "+--------------------+--------------------+---------+--------------------+\n",
      "|     JUMBO BAG PEARS| [jumbo, bag, pears]|    503.0|     JUMBO BAG PEARS|\n",
      "|  JUMBO BAG ALPHABET|[jumbo, bag, alph...|    106.0|  JUMBO BAG ALPHABET|\n",
      "|    JUMBO BAG APPLES|[jumbo, bag, apples]|    107.0|    JUMBO BAG APPLES|\n",
      "|JUMBO BAG STRAWBERRY|[jumbo, bag, stra...|    505.0|JUMBO BAG STRAWBERRY|\n",
      "|JUMBO BAG RED RET...|[jumbo, bag, red,...|      3.0|JUMBO BAG RED RET...|\n",
      "+--------------------+--------------------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import IndexToString, StringIndexer\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"Description\", outputCol=\"DescIndex\")\n",
    "model = indexer.fit(data)\n",
    "indexed = model.transform(data)\n",
    "\n",
    "converter = IndexToString(inputCol=\"DescIndex\", outputCol=\"originalDescription\")\n",
    "converted = converter.transform(indexed)\n",
    "\n",
    "converted.select(\"Description\", \"DescOut\", \"DescIndex\", \"originalDescription\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "aeb73826",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------------------------+---------+--------------------+------------------+\n",
      "|         Description|             DescOut|StopWordsRemover_d5f3719445d6__output|DescIndex| originalDescription|           DescVec|\n",
      "+--------------------+--------------------+-------------------------------------+---------+--------------------+------------------+\n",
      "|     JUMBO BAG PEARS| [jumbo, bag, pears]|                  [jumbo, bag, pears]|    503.0|     JUMBO BAG PEARS|(1199,[503],[1.0])|\n",
      "|  JUMBO BAG ALPHABET|[jumbo, bag, alph...|                 [jumbo, bag, alph...|    106.0|  JUMBO BAG ALPHABET|(1199,[106],[1.0])|\n",
      "|    JUMBO BAG APPLES|[jumbo, bag, apples]|                 [jumbo, bag, apples]|    107.0|    JUMBO BAG APPLES|(1199,[107],[1.0])|\n",
      "|JUMBO BAG STRAWBERRY|[jumbo, bag, stra...|                 [jumbo, bag, stra...|    505.0|JUMBO BAG STRAWBERRY|(1199,[505],[1.0])|\n",
      "|JUMBO BAG RED RET...|[jumbo, bag, red,...|                 [jumbo, bag, red,...|      3.0|JUMBO BAG RED RET...|  (1199,[3],[1.0])|\n",
      "+--------------------+--------------------+-------------------------------------+---------+--------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import OneHotEncoder\n",
    "\n",
    "encoder = OneHotEncoder(inputCols=[\"DescIndex\"],\n",
    "                        outputCols=[\"DescVec\"])\n",
    "model = encoder.fit(converted)\n",
    "encoded = model.transform(converted)\n",
    "encoded.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56396c98",
   "metadata": {},
   "source": [
    "### 4. Represent every Description text with a sum of those vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d536a051",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------------+----------------------------+\n",
      "|features          |Description            |DescOut                     |\n",
      "+------------------+-----------------------+----------------------------+\n",
      "|(1199,[503],[1.0])|JUMBO BAG PEARS        |[jumbo, bag, pears]         |\n",
      "|(1199,[106],[1.0])|JUMBO BAG ALPHABET     |[jumbo, bag, alphabet]      |\n",
      "|(1199,[107],[1.0])|JUMBO BAG APPLES       |[jumbo, bag, apples]        |\n",
      "|(1199,[505],[1.0])|JUMBO BAG STRAWBERRY   |[jumbo, bag, strawberry]    |\n",
      "|(1199,[3],[1.0])  |JUMBO BAG RED RETROSPOT|[jumbo, bag, red, retrospot]|\n",
      "+------------------+-----------------------+----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"DescVec\"],\n",
    "    outputCol=\"features\")\n",
    "\n",
    "output = assembler.transform(encoded)\n",
    "\n",
    "output.select(\"features\", \"Description\", \"DescOut\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6d770275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|Description                     |Quantity|InvoiceDate        |UnitPrice|CustomerID|Country       |\n",
      "+---------+---------+--------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "|569415   |23295    |SET OF 12 MINI LOAF BAKING CASES|3       |2011-10-04 10:14:00|2.46     |null      |United Kingdom|\n",
      "|569479   |23295    |SET OF 12 MINI LOAF BAKING CASES|24      |2011-10-04 12:41:00|0.83     |13408.0   |United Kingdom|\n",
      "|569523   |23295    |SET OF 12 MINI LOAF BAKING CASES|8       |2011-10-04 14:41:00|0.83     |16033.0   |United Kingdom|\n",
      "|569532   |23295    |SET OF 12 MINI LOAF BAKING CASES|16      |2011-10-04 15:19:00|0.83     |13552.0   |United Kingdom|\n",
      "|569545   |23295    |SET OF 12 MINI LOAF BAKING CASES|2       |2011-10-04 16:37:00|2.46     |null      |United Kingdom|\n",
      "|569546   |23295    |SET OF 12 MINI LOAF BAKING CASES|3       |2011-10-04 16:39:00|0.83     |15276.0   |United Kingdom|\n",
      "+---------+---------+--------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales.filter(sales.Description == \"SET OF 12 MINI LOAF BAKING CASES\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8fe6300d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pyspark.ml.linalg import *\n",
    "from pyspark.sql.types import * \n",
    "from pyspark.sql.functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9b40c522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos_sim(a,b):\n",
    "    return float(np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "40029796",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'numpy.float64' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_18100/1462446393.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"coSim\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mudf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcos_sim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFloatType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstatic_vector\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_18100/1462446393.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"coSim\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mudf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcos_sim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mFloatType\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"features\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mstatic_vector\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlimit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoPandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'numpy.float64' object is not iterable"
     ]
    }
   ],
   "source": [
    "df = output.withColumn(\"coSim\", udf(cos_sim, FloatType())(col(\"features\"), array([list(v) for v in static_vector])))\n",
    "df.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "258d1b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"Description\", outputCol=\"descWords\")\n",
    "descData = tokenizer.transform(sales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6ef04baf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+--------------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|           descWords|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+--------------------+\n",
      "|   569397|    23200|     JUMBO BAG PEARS|      10|2011-10-04 08:26:00|     2.08|   12747.0|United Kingdom| [jumbo, bag, pears]|\n",
      "|   569397|    23201|  JUMBO BAG ALPHABET|      10|2011-10-04 08:26:00|     2.08|   12747.0|United Kingdom|[jumbo, bag, alph...|\n",
      "|   569397|    23199|    JUMBO BAG APPLES|      10|2011-10-04 08:26:00|     2.08|   12747.0|United Kingdom|[jumbo, bag, apples]|\n",
      "|   569397|   85099F|JUMBO BAG STRAWBERRY|      10|2011-10-04 08:26:00|     2.08|   12747.0|United Kingdom|[jumbo, bag, stra...|\n",
      "|   569397|   85099B|JUMBO BAG RED RET...|      10|2011-10-04 08:26:00|     2.08|   12747.0|United Kingdom|[jumbo, bag, red,...|\n",
      "|   569397|    22386|JUMBO BAG PINK PO...|      10|2011-10-04 08:26:00|     2.08|   12747.0|United Kingdom|[jumbo, bag, pink...|\n",
      "|   569397|    48138|  DOORMAT UNION FLAG|       2|2011-10-04 08:26:00|     8.25|   12747.0|United Kingdom|[doormat, union, ...|\n",
      "|   569397|    22120|WELCOME  WOODEN B...|       3|2011-10-04 08:26:00|     9.95|   12747.0|United Kingdom|[welcome, , woode...|\n",
      "|   569397|   85123A|WHITE HANGING HEA...|      12|2011-10-04 08:26:00|     2.95|   12747.0|United Kingdom|[white, hanging, ...|\n",
      "|   569397|    21754|HOME BUILDING BLO...|       3|2011-10-04 08:26:00|     6.25|   12747.0|United Kingdom|[home, building, ...|\n",
      "|   569397|    82482|WOODEN PICTURE FR...|      36|2011-10-04 08:26:00|     2.55|   12747.0|United Kingdom|[wooden, picture,...|\n",
      "|   569397|    82484|WOOD BLACK BOARD ...|      36|2011-10-04 08:26:00|     6.75|   12747.0|United Kingdom|[wood, black, boa...|\n",
      "|   569397|   82494L|WOODEN FRAME ANTI...|      24|2011-10-04 08:26:00|     2.55|   12747.0|United Kingdom|[wooden, frame, a...|\n",
      "|   569397|    84879|ASSORTED COLOUR B...|      16|2011-10-04 08:26:00|     1.69|   12747.0|United Kingdom|[assorted, colour...|\n",
      "|   569397|    21136|PAINTED METAL PEA...|      16|2011-10-04 08:26:00|     1.69|   12747.0|United Kingdom|[painted, metal, ...|\n",
      "|   569398|    22563| HAPPY STENCIL CRAFT|     144|2011-10-04 08:27:00|     1.06|   17381.0|United Kingdom|[happy, stencil, ...|\n",
      "|   569398|    22564|ALPHABET STENCIL ...|      48|2011-10-04 08:27:00|     1.06|   17381.0|United Kingdom|[alphabet, stenci...|\n",
      "|   569398|    21790|  VINTAGE SNAP CARDS|     216|2011-10-04 08:27:00|     0.72|   17381.0|United Kingdom|[vintage, snap, c...|\n",
      "|   569399|    22560|TRADITIONAL MODEL...|     192|2011-10-04 08:29:00|     1.06|   17381.0|United Kingdom|[traditional, mod...|\n",
      "|   569399|    22492|MINI PAINT SET VI...|     576|2011-10-04 08:29:00|     0.55|   17381.0|United Kingdom|[mini, paint, set...|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "descData.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5b0f80fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', \"i'll\", \"you'll\", \"he'll\", \"she'll\", \"we'll\", \"they'll\", \"i'd\", \"you'd\", \"he'd\", \"she'd\", \"we'd\", \"they'd\", \"i'm\", \"you're\", \"he's\", \"she's\", \"it's\", \"we're\", \"they're\", \"i've\", \"we've\", \"you've\", \"they've\", \"isn't\", \"aren't\", \"wasn't\", \"weren't\", \"haven't\", \"hasn't\", \"hadn't\", \"don't\", \"doesn't\", \"didn't\", \"won't\", \"wouldn't\", \"shan't\", \"shouldn't\", \"mustn't\", \"can't\", \"couldn't\", 'cannot', 'could', \"here's\", \"how's\", \"let's\", 'ought', \"that's\", \"there's\", \"what's\", \"when's\", \"where's\", \"who's\", \"why's\", 'would']\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover\n",
    "englishStopWords = StopWordsRemover.loadDefaultStopWords(\"english\")\n",
    "print(englishStopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "61423517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-----------------------+--------+-------------------+---------+----------+--------------+----------------------------+-------------------------------------+\n",
      "|InvoiceNo|StockCode|Description            |Quantity|InvoiceDate        |UnitPrice|CustomerID|Country       |descWords                   |StopWordsRemover_62764232d3d1__output|\n",
      "+---------+---------+-----------------------+--------+-------------------+---------+----------+--------------+----------------------------+-------------------------------------+\n",
      "|569397   |23200    |JUMBO BAG PEARS        |10      |2011-10-04 08:26:00|2.08     |12747.0   |United Kingdom|[jumbo, bag, pears]         |[jumbo, bag, pears]                  |\n",
      "|569397   |23201    |JUMBO BAG ALPHABET     |10      |2011-10-04 08:26:00|2.08     |12747.0   |United Kingdom|[jumbo, bag, alphabet]      |[jumbo, bag, alphabet]               |\n",
      "|569397   |23199    |JUMBO BAG APPLES       |10      |2011-10-04 08:26:00|2.08     |12747.0   |United Kingdom|[jumbo, bag, apples]        |[jumbo, bag, apples]                 |\n",
      "|569397   |85099F   |JUMBO BAG STRAWBERRY   |10      |2011-10-04 08:26:00|2.08     |12747.0   |United Kingdom|[jumbo, bag, strawberry]    |[jumbo, bag, strawberry]             |\n",
      "|569397   |85099B   |JUMBO BAG RED RETROSPOT|10      |2011-10-04 08:26:00|2.08     |12747.0   |United Kingdom|[jumbo, bag, red, retrospot]|[jumbo, bag, red, retrospot]         |\n",
      "+---------+---------+-----------------------+--------+-------------------+---------+----------+--------------+----------------------------+-------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover\n",
    "englishStopWords = StopWordsRemover.loadDefaultStopWords(\"english\")\n",
    "stops = StopWordsRemover()\\\n",
    ".setStopWords(englishStopWords)\\\n",
    ".setInputCol(\"descWords\")\n",
    "stops.transform(descData).show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "da980636",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = stops.transform(descData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "490a4283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+--------------------+--------------------+\n",
      "|InvoiceNo|StockCode|         Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|           descWords|         rawFeatures|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+--------------------+--------------------+\n",
      "|   569397|    23200|     JUMBO BAG PEARS|      10|2011-10-04 08:26:00|     2.08|   12747.0|United Kingdom| [jumbo, bag, pears]|(20,[4,12,15],[1....|\n",
      "|   569397|    23201|  JUMBO BAG ALPHABET|      10|2011-10-04 08:26:00|     2.08|   12747.0|United Kingdom|[jumbo, bag, alph...|(20,[3,4,15],[1.0...|\n",
      "|   569397|    23199|    JUMBO BAG APPLES|      10|2011-10-04 08:26:00|     2.08|   12747.0|United Kingdom|[jumbo, bag, apples]|(20,[4,5,15],[1.0...|\n",
      "|   569397|   85099F|JUMBO BAG STRAWBERRY|      10|2011-10-04 08:26:00|     2.08|   12747.0|United Kingdom|[jumbo, bag, stra...|(20,[4,12,15],[1....|\n",
      "|   569397|   85099B|JUMBO BAG RED RET...|      10|2011-10-04 08:26:00|     2.08|   12747.0|United Kingdom|[jumbo, bag, red,...|(20,[4,8,12,15],[...|\n",
      "+---------+---------+--------------------+--------+-------------------+---------+----------+--------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import HashingTF, IDF, Tokenizer\n",
    "hashingTF = HashingTF(inputCol=\"descWords\", outputCol=\"rawFeatures\", numFeatures=20)\n",
    "featurizedData = hashingTF.transform(descData)\n",
    "\n",
    "featurizedData.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fd0f8f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+--------------------+\n",
      "|         Description|           descWords|            features|\n",
      "+--------------------+--------------------+--------------------+\n",
      "|     JUMBO BAG PEARS| [jumbo, bag, pears]|(20,[4,12,15],[1....|\n",
      "|  JUMBO BAG ALPHABET|[jumbo, bag, alph...|(20,[3,4,15],[1.5...|\n",
      "|    JUMBO BAG APPLES|[jumbo, bag, apples]|(20,[4,5,15],[1.5...|\n",
      "|JUMBO BAG STRAWBERRY|[jumbo, bag, stra...|(20,[4,12,15],[1....|\n",
      "|JUMBO BAG RED RET...|[jumbo, bag, red,...|(20,[4,8,12,15],[...|\n",
      "+--------------------+--------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
    "idfModel = idf.fit(featurizedData)\n",
    "rescaledData = idfModel.transform(featurizedData)\n",
    "rescaledData.select(\"Description\", \"descWords\", \"features\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6392bf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|Description                     |Quantity|InvoiceDate        |UnitPrice|CustomerID|Country       |\n",
      "+---------+---------+--------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "|569415   |23295    |SET OF 12 MINI LOAF BAKING CASES|3       |2011-10-04 10:14:00|2.46     |null      |United Kingdom|\n",
      "|569479   |23295    |SET OF 12 MINI LOAF BAKING CASES|24      |2011-10-04 12:41:00|0.83     |13408.0   |United Kingdom|\n",
      "|569523   |23295    |SET OF 12 MINI LOAF BAKING CASES|8       |2011-10-04 14:41:00|0.83     |16033.0   |United Kingdom|\n",
      "|569532   |23295    |SET OF 12 MINI LOAF BAKING CASES|16      |2011-10-04 15:19:00|0.83     |13552.0   |United Kingdom|\n",
      "|569545   |23295    |SET OF 12 MINI LOAF BAKING CASES|2       |2011-10-04 16:37:00|2.46     |null      |United Kingdom|\n",
      "|569546   |23295    |SET OF 12 MINI LOAF BAKING CASES|3       |2011-10-04 16:39:00|0.83     |15276.0   |United Kingdom|\n",
      "+---------+---------+--------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales.filter(sales.Description == \"SET OF 12 MINI LOAF BAKING CASES\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7b08f874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           descWords|\n",
      "+--------------------+\n",
      "|[set, of, 12, min...|\n",
      "|[set, of, 12, min...|\n",
      "|[set, of, 12, min...|\n",
      "|[set, of, 6, snac...|\n",
      "|[set, of, 12, min...|\n",
      "|[set, of, 6, snac...|\n",
      "|[set, of, 12, min...|\n",
      "|[set, of, 12, min...|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tfIdfIn = data\\\n",
    ".where(\"array_contains(descWords, 'loaf')\")\\\n",
    ".select(\"descWords\")\n",
    "tfIdfIn.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "c1bb89a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+----------------------------+\n",
      "|Description            |DescOut                     |\n",
      "+-----------------------+----------------------------+\n",
      "|JUMBO BAG PEARS        |[jumbo, bag, pears]         |\n",
      "|JUMBO BAG ALPHABET     |[jumbo, bag, alphabet]      |\n",
      "|JUMBO BAG APPLES       |[jumbo, bag, apples]        |\n",
      "|JUMBO BAG STRAWBERRY   |[jumbo, bag, strawberry]    |\n",
      "|JUMBO BAG RED RETROSPOT|[jumbo, bag, red, retrospot]|\n",
      "+-----------------------+----------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#tokenize string from Description column, splitting on a given character\n",
    "from pyspark.ml.feature import Tokenizer\n",
    "tkn = Tokenizer().setInputCol(\"Description\").setOutputCol(\"DescOut\")\n",
    "tokenized = tkn.transform(sales.select(\"Description\"))\n",
    "tokenized.show(5, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7db6214d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', \"i'll\", \"you'll\", \"he'll\", \"she'll\", \"we'll\", \"they'll\", \"i'd\", \"you'd\", \"he'd\", \"she'd\", \"we'd\", \"they'd\", \"i'm\", \"you're\", \"he's\", \"she's\", \"it's\", \"we're\", \"they're\", \"i've\", \"we've\", \"you've\", \"they've\", \"isn't\", \"aren't\", \"wasn't\", \"weren't\", \"haven't\", \"hasn't\", \"hadn't\", \"don't\", \"doesn't\", \"didn't\", \"won't\", \"wouldn't\", \"shan't\", \"shouldn't\", \"mustn't\", \"can't\", \"couldn't\", 'cannot', 'could', \"here's\", \"how's\", \"let's\", 'ought', \"that's\", \"there's\", \"what's\", \"when's\", \"where's\", \"who's\", \"why's\", 'would']\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover\n",
    "englishStopWords = StopWordsRemover.loadDefaultStopWords(\"english\")\n",
    "print(englishStopWords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "b9f5d817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+----------------------------+-------------------------------------+\n",
      "|Description            |DescOut                     |StopWordsRemover_1e470ba46cc6__output|\n",
      "+-----------------------+----------------------------+-------------------------------------+\n",
      "|JUMBO BAG PEARS        |[jumbo, bag, pears]         |[jumbo, bag, pears]                  |\n",
      "|JUMBO BAG ALPHABET     |[jumbo, bag, alphabet]      |[jumbo, bag, alphabet]               |\n",
      "|JUMBO BAG APPLES       |[jumbo, bag, apples]        |[jumbo, bag, apples]                 |\n",
      "|JUMBO BAG STRAWBERRY   |[jumbo, bag, strawberry]    |[jumbo, bag, strawberry]             |\n",
      "|JUMBO BAG RED RETROSPOT|[jumbo, bag, red, retrospot]|[jumbo, bag, red, retrospot]         |\n",
      "+-----------------------+----------------------------+-------------------------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.feature import StopWordsRemover\n",
    "englishStopWords = StopWordsRemover.loadDefaultStopWords(\"english\")\n",
    "stops = StopWordsRemover()\\\n",
    ".setStopWords(englishStopWords)\\\n",
    ".setInputCol(\"DescOut\")\n",
    "stops.transform(tokenized).show(5,False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ba5361d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = stops.transform(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "01faa318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word2Vec_d05a514d93a0"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import Word2Vec\n",
    "word2Vec = Word2Vec(vectorSize=3, minCount=0, inputCol=\"DescOut\",\n",
    "outputCol=\"result\")\n",
    "\n",
    "word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "3ccc0dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+-------------------------------------+--------------------+\n",
      "|         Description|             DescOut|StopWordsRemover_1e470ba46cc6__output|              result|\n",
      "+--------------------+--------------------+-------------------------------------+--------------------+\n",
      "|     JUMBO BAG PEARS| [jumbo, bag, pears]|                  [jumbo, bag, pears]|[0.30474084119002...|\n",
      "|  JUMBO BAG ALPHABET|[jumbo, bag, alph...|                 [jumbo, bag, alph...|[0.46335827310880...|\n",
      "|    JUMBO BAG APPLES|[jumbo, bag, apples]|                 [jumbo, bag, apples]|[0.40410287181536...|\n",
      "|JUMBO BAG STRAWBERRY|[jumbo, bag, stra...|                 [jumbo, bag, stra...|[0.38322112957636...|\n",
      "|JUMBO BAG RED RET...|[jumbo, bag, red,...|                 [jumbo, bag, red,...|[0.26491938793333...|\n",
      "+--------------------+--------------------+-------------------------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = word2Vec.fit(data)\n",
    "result = model.transform(data)\n",
    "result.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5e26cbc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+--------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|Description                     |Quantity|InvoiceDate        |UnitPrice|CustomerID|Country       |\n",
      "+---------+---------+--------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "|569415   |23295    |SET OF 12 MINI LOAF BAKING CASES|3       |2011-10-04 10:14:00|2.46     |null      |United Kingdom|\n",
      "|569479   |23295    |SET OF 12 MINI LOAF BAKING CASES|24      |2011-10-04 12:41:00|0.83     |13408.0   |United Kingdom|\n",
      "|569523   |23295    |SET OF 12 MINI LOAF BAKING CASES|8       |2011-10-04 14:41:00|0.83     |16033.0   |United Kingdom|\n",
      "|569532   |23295    |SET OF 12 MINI LOAF BAKING CASES|16      |2011-10-04 15:19:00|0.83     |13552.0   |United Kingdom|\n",
      "|569545   |23295    |SET OF 12 MINI LOAF BAKING CASES|2       |2011-10-04 16:37:00|2.46     |null      |United Kingdom|\n",
      "|569546   |23295    |SET OF 12 MINI LOAF BAKING CASES|3       |2011-10-04 16:39:00|0.83     |15276.0   |United Kingdom|\n",
      "+---------+---------+--------------------------------+--------+-------------------+---------+----------+--------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sales.filter(sales.Description == \"SET OF 12 MINI LOAF BAKING CASES\").show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "243c75ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b0d9ae34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>InvoiceNo</th>\n",
       "      <th>StockCode</th>\n",
       "      <th>Description</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>InvoiceDate</th>\n",
       "      <th>UnitPrice</th>\n",
       "      <th>CustomerID</th>\n",
       "      <th>Country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>569397</td>\n",
       "      <td>23200</td>\n",
       "      <td>JUMBO BAG PEARS</td>\n",
       "      <td>10</td>\n",
       "      <td>2011-10-04 08:26:00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>12747.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>569397</td>\n",
       "      <td>23201</td>\n",
       "      <td>JUMBO BAG ALPHABET</td>\n",
       "      <td>10</td>\n",
       "      <td>2011-10-04 08:26:00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>12747.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>569397</td>\n",
       "      <td>23199</td>\n",
       "      <td>JUMBO BAG APPLES</td>\n",
       "      <td>10</td>\n",
       "      <td>2011-10-04 08:26:00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>12747.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>569397</td>\n",
       "      <td>85099F</td>\n",
       "      <td>JUMBO BAG STRAWBERRY</td>\n",
       "      <td>10</td>\n",
       "      <td>2011-10-04 08:26:00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>12747.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>569397</td>\n",
       "      <td>85099B</td>\n",
       "      <td>JUMBO BAG RED RETROSPOT</td>\n",
       "      <td>10</td>\n",
       "      <td>2011-10-04 08:26:00</td>\n",
       "      <td>2.08</td>\n",
       "      <td>12747.0</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  InvoiceNo StockCode              Description  Quantity          InvoiceDate  \\\n",
       "0    569397     23200          JUMBO BAG PEARS        10  2011-10-04 08:26:00   \n",
       "1    569397     23201       JUMBO BAG ALPHABET        10  2011-10-04 08:26:00   \n",
       "2    569397     23199         JUMBO BAG APPLES        10  2011-10-04 08:26:00   \n",
       "3    569397    85099F     JUMBO BAG STRAWBERRY        10  2011-10-04 08:26:00   \n",
       "4    569397    85099B  JUMBO BAG RED RETROSPOT        10  2011-10-04 08:26:00   \n",
       "\n",
       "   UnitPrice  CustomerID         Country  \n",
       "0       2.08     12747.0  United Kingdom  \n",
       "1       2.08     12747.0  United Kingdom  \n",
       "2       2.08     12747.0  United Kingdom  \n",
       "3       2.08     12747.0  United Kingdom  \n",
       "4       2.08     12747.0  United Kingdom  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retail_df = pd.read_csv(\"retail-data/by-day/2011-10-04.csv\")\n",
    "retail_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "56c635c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/f_dev/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "retail_df['Description']= retail_df['Description'].apply(str)\n",
    "\n",
    "desc = list(retail_df['Description'])\n",
    "\n",
    "def get_tokens(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    return tokens\n",
    "\n",
    "desc_tokens = [get_tokens(text) for text in desc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2b59cbd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'no', \"mustn't\", 'himself', 'what', 'isn', 'that', 'she', 'being', 'didn', \"mightn't\", 'aren', 'i', \"she's\", 'will', 'are', \"didn't\", 'o', 'itself', 'ma', 'for', 'once', 'so', 'which', 'such', 'we', 'd', \"you'll\", 'doesn', 'mustn', 'nor', \"aren't\", \"it's\", 've', 'the', 'having', \"isn't\", 'under', 'of', 'more', 't', 'll', 're', 'through', 'theirs', 'to', 'shan', \"needn't\", 'after', 'during', 'most', 'yourselves', 'don', 'ourselves', 'just', 'had', 'there', 'it', 'won', 'whom', 'how', 'hadn', 'herself', \"hadn't\", 'in', 'mightn', 'over', 'where', 'was', 'shouldn', 'is', 'ours', 'our', 'this', 'and', 'myself', 'these', \"won't\", 'before', 's', 'do', 'me', 'did', 'both', 'why', \"shan't\", 'until', 'themselves', 'be', 'yours', 'while', 'against', 'own', 'between', 'on', 'been', 'its', 'again', 'about', 'some', 'out', 'who', \"shouldn't\", 'weren', 'wasn', 'hasn', 'their', 'your', 'here', 'haven', 'his', \"couldn't\", 'ain', 'my', 'off', \"that'll\", 'you', 'at', 'too', 'y', 'an', 'were', 'any', 'few', 'can', 'above', 'below', \"doesn't\", \"wouldn't\", 'with', 'when', 'am', 'has', 'each', 'm', 'or', 'if', 'but', 'because', \"you'd\", 'does', 'him', 'should', 'they', 'a', 'them', 'not', 'only', 'very', \"haven't\", 'couldn', \"don't\", 'have', 'further', 'same', \"wasn't\", 'into', 'by', \"weren't\", 'than', \"hasn't\", 'he', \"you've\", 'hers', 'doing', \"you're\", 'those', 'all', 'other', \"should've\", 'down', 'needn', 'yourself', 'her', 'wouldn', 'now', 'up', 'as', 'from', 'then'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/f_dev/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "english_stopwords = set(nltk.corpus.stopwords.words('english'))\n",
    "print(english_stopwords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
