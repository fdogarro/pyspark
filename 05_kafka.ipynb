{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f82aca9",
   "metadata": {},
   "source": [
    "### Connecting from my host machine to my VM using SSH\n",
    "\n",
    "SSH Command -> ```ssh {USERNAME}@{VIRTUAL_MACHINE_IP_ADDRESS}``` </br>\n",
    "\n",
    "Enter passphrase for key '/Users/{USERNAME}/.ssh/id_rsa': ```{password}```</br>\n",
    "\n",
    "Welcome to Ubuntu 20.04.3 LTS (GNU/Linux 5.4.0-100-generic x86_64) </br>\n",
    "\n",
    " * Documentation:  https://help.ubuntu.com\n",
    " * Management:     https://landscape.canonical.com\n",
    " * Support:        https://ubuntu.com/advantage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4db2ff",
   "metadata": {},
   "source": [
    "### Using linux systemctl to start, stop and check the status of zookeeper and kafka\n",
    "\n",
    "### Zookeeper\n",
    "\n",
    "Starting Zookeeper -> ```sudo systemctl start zookeeper```</br>\n",
    "\n",
    "zookeeper.service\n",
    "     Loaded: loaded (/etc/systemd/system/zookeeper.service; enabled; vendor preset: enabled)\n",
    "     Active: active (running) since Sat 2022-03-05 04:57:08 UTC; 4h 21min ago\n",
    "   Main PID: 19306 (java)\n",
    "      Tasks: 27 (limit: 2339)\n",
    "\n",
    "</br>\n",
    "\n",
    "Stopping Zookeeper -> ```sudo systemctl stop zookeeper```</br>\n",
    "\n",
    "zookeeper.service\n",
    "     Loaded: loaded (/etc/systemd/system/zookeeper.service; enabled; vendor preset: enabled)\n",
    "     Active: failed (Result: exit-code) since Sat 2022-03-05 09:24:52 UTC; 9s ago\n",
    "    Process: 19306 ExecStart=/opt/kafka/bin/zookeeper-server-start.sh /opt/kafka/config/zookeeper.properties (code=exited, status=143)\n",
    "    Process: 25422 ExecStop=/opt/kafka/bin/zookeeper-server-stop.sh (code=exited, status=0/SUCCESS)\n",
    "   Main PID: 19306 (code=exited, status=143)\n",
    "   \n",
    "</br>\n",
    "\n",
    "Checking Zookeeper Status -> ```sudo systemctl status zookeeper```</br>\n",
    "\n",
    "### Kafka\n",
    "\n",
    "Starting Kafka -> ```sudo systemctl start kafka``` </br>\n",
    "\n",
    "kafka.service\n",
    "     Loaded: loaded (/etc/systemd/system/kafka.service; enabled; vendor preset: enabled)\n",
    "     Active: active (running) since Sat 2022-03-05 05:12:46 UTC; 4h 9min ago\n",
    "   Main PID: 22340 (sh)\n",
    "      Tasks: 71 (limit: 2339)\n",
    "     Memory: 359.6M\n",
    "\n",
    "\n",
    "Stopping Kafka --> ```sudo systemctl stop kafka``` </br>\n",
    "\n",
    "kafka.service\n",
    "     Loaded: loaded (/etc/systemd/system/kafka.service; enabled; vendor preset: enabled)\n",
    "     Active: inactive (dead) since Sat 2022-03-05 09:24:52 UTC; 2min 12s ago\n",
    "    Process: 22340 ExecStart=/bin/sh -c /opt/kafka/bin/kafka-server-start.sh /opt/kafka/config/server.properties > /opt/kafka/kafka.log 2>&1 (code=killed,>\n",
    "    Process: 25408 ExecStop=/opt/kafka/bin/kafka-server-stop.sh (code=exited, status=0/SUCCESS)\n",
    "   Main PID: 22340 (code=killed, signal=TERM)\n",
    "\n",
    "</br>\n",
    "\n",
    "Checking Kafka Status -> ```sudo systemctl status kafka``` </br>\n",
    "\n",
    "### Confirming that Zookeeper is listening on port 2182 and Kafka on port 9092\n",
    "Confirming Zookeeper is listening on port 2182 -> ```sudo netstat –tunlp | grep 2181```</br>\n",
    "Confirming Kafka is listening on port 9092 -> ```sudo netstat –tunlp | grep 9092```</br>\n",
    "\n",
    "### Create two new topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c9b6441",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Topic1': <Future at 0x7f585402c910 state=running>,\n",
       " 'Topic2': <Future at 0x7f58456261f0 state=running>}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#use confluent kafka to create admin client and two topics\n",
    "\n",
    "from confluent_kafka.admin import AdminClient, NewTopic\n",
    "\n",
    "admin_client = AdminClient({\n",
    "    \"bootstrap.servers\": \"localhost:9092\"\n",
    "})\n",
    "\n",
    "topic_list = []\n",
    "topic_list.append(NewTopic(\"Topic1\", 1, 1))\n",
    "topic_list.append(NewTopic(\"Topic2\", 1, 1))\n",
    "admin_client.create_topics(topic_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ab3ae0",
   "metadata": {},
   "source": [
    "After publishing and consuming the messages I received the log down below from the broker connection. (I'm attaching seperate python scripts since I'm unable to publish messages for both problem 3 and 4 in jupyter notebook since it's single threaded)\n",
    "\n",
    "got msg ConsumerRecord(topic='Test3', partition=0, offset=32, timestamp=1646496365256, timestamp_type=0, key=None, value=b'test3 message', headers=[], checksum=None, serialized_key_size=-1, serialized_value_size=13, serialized_header_size=-1)\n",
    "0 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59f8990b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<kafka.producer.future.FutureRecordMetadata at 0x7f584443cfd0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from kafka import KafkaProducer, KafkaConsumer\n",
    "\n",
    "topic = 'Test3'\n",
    "producer = KafkaProducer(bootstrap_servers='localhost:9092')\n",
    "\n",
    "producer.send(topic, b'test3 message')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17024401",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from kafka import KafkaConsumer, TopicPartition\n",
    "from kafka.errors import KafkaError\n",
    "import logging\n",
    "import sys\n",
    "from kafka.errors import OffsetOutOfRangeError\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "def main2(broker_str, topic):\n",
    "    try:\n",
    "        consumer = KafkaConsumer(group_id='my-group', bootstrap_servers=['localhost:9092'], auto_offset_reset=\"latest\")\n",
    "        consumer.subscribe([topic])\n",
    "        while True:\n",
    "            try:\n",
    "                k_msg = consumer.poll(timeout_ms=200)\n",
    "            except OffsetOutOfRangeError:\n",
    "                log.info(\"Offset out of range\")\n",
    "            else:\n",
    "                if k_msg:\n",
    "                    for msgs in list(k_msg.values()):\n",
    "                        for msg in msgs:\n",
    "                            print(\"got msg\", str(msg))\n",
    "                            print(msg.partition, msg.offset)\n",
    "    except:\n",
    "        print(\"executution error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f81e430",
   "metadata": {},
   "outputs": [],
   "source": [
    "main2('localhost:9092', 'Test3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3bc4e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Topic1': <Future at 0x7f58443db430 state=finished raised KafkaException>,\n",
       " 'Topic2': <Future at 0x7f58443db4f0 state=finished raised KafkaException>,\n",
       " 'Test22': <Future at 0x7f58443db5e0 state=finished raised KafkaException>}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create topic to start the producer and consumer\n",
    "\n",
    "# from confluent_kafka.admin import AdminClient, NewTopic\n",
    "\n",
    "\n",
    "# admin_client = AdminClient({\n",
    "#     \"bootstrap.servers\": \"localhost:9092\"\n",
    "# })\n",
    "\n",
    "# topic_list = []\n",
    "topic_list.append(NewTopic(\"Test22\", 1, 1))\n",
    "admin_client.create_topics(topic_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed46f96",
   "metadata": {},
   "source": [
    "#### Producer Code from page 53 of the lecture notes\n",
    "\n",
    "In order to get the below to work we needed to change the way that we were concatenating the byte to a string for the second argument in the producer.send method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90073dfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting batch #0\n",
      "sending message #0\n",
      "sending message #1\n",
      "sending message #2\n",
      "sending message #3\n",
      "Finished batch #0\n",
      "Sleeping for 5 seconds ...\n",
      "Starting batch #1\n",
      "sending message #0\n",
      "sending message #1\n",
      "sending message #2\n",
      "sending message #3\n",
      "Finished batch #1\n",
      "Sleeping for 5 seconds ...\n",
      "Starting batch #2\n",
      "sending message #0\n",
      "sending message #1\n",
      "sending message #2\n",
      "sending message #3\n",
      "Finished batch #2\n",
      "Sleeping for 5 seconds ...\n",
      "Done sending messages\n"
     ]
    }
   ],
   "source": [
    "from kafka import KafkaProducer\n",
    "import time\n",
    "topic = 'Test22'\n",
    "producer = KafkaProducer(bootstrap_servers='localhost:9092')\n",
    "\n",
    "for batch in range(3):\n",
    "    print('Starting batch #' + str(batch))\n",
    "    for i in range(4):\n",
    "        print('sending message #' + str(i))\n",
    "        # needed to update code to concatenate a byte and a string\n",
    "        producer.send(topic, b'test message #'.join([str(i).encode('utf-8')]))\n",
    "    print('Finished batch #' + str(batch))\n",
    "    print('Sleeping for 5 seconds ...')\n",
    "    time.sleep(5)\n",
    "print('Done sending messages')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d215716",
   "metadata": {},
   "source": [
    "#### Consumer Code from page 54 and 55 of the lecture notes\n",
    "\n",
    "In order to get the below working I added an except block to end the try/except block and invoked the main function by passing in the broker str as the first argument and the topic as the second."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b113ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from kafka import KafkaConsumer, TopicPartition\n",
    "from kafka.errors import KafkaError\n",
    "import logging\n",
    "import sys\n",
    "from kafka.errors import OffsetOutOfRangeError\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "log = logging.getLogger(__name__)\n",
    "\n",
    "def main(broker_str, topic):\n",
    "#topic = \"Test22\"\n",
    "    group = \"my-group1\"\n",
    "#bootstrap_servers = ['localhost:9092']\n",
    "    bootstrap_servers = [broker_str]\n",
    "    print('Topic is: ', topic)\n",
    "    print('Group is: ', group)\n",
    "    \n",
    "    try:\n",
    "        consumer = KafkaConsumer(group_id=group, bootstrap_servers=bootstrap_servers,auto_offset_reset=\"latest\")\n",
    "        consumer.subscribe([topic])     \n",
    "        while True:\n",
    "    # Process messages\n",
    "            try:\n",
    "                k_msg = consumer.poll(timeout_ms=200)\n",
    "            except OffsetOutOfRangeError:\n",
    "                log.info(\"Offset out of range. Seeking to begining\")\n",
    "                # consumer.seek_to_beginning(tp)\n",
    "                # You can save `consumer.position(tp)` to redis after this,\n",
    "                # but it will be saved after next message anyway\n",
    "            else:\n",
    "                if k_msg:\n",
    "                    for msgs in list(k_msg.values()):\n",
    "                        for msg in msgs:\n",
    "                            print('got msg: ', str(msg))\n",
    "                            # Process message and increment offset\n",
    "                            print('partition: ', msg.partition, 'message offset: ', msg.offset)\n",
    "    except:\n",
    "        print(\"execution completed\")\n",
    "        consumer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8c015a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]>: connecting to localhost:9092 [('127.0.0.1', 9092) IPv4]\n",
      "INFO:kafka.conn:Probing node bootstrap-0 broker version\n",
      "INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]>: Connection complete.\n",
      "INFO:kafka.conn:Broker version identified as 2.5.0\n",
      "INFO:kafka.conn:Set configuration api_version=(2, 5, 0) to skip auto check_version requests on startup\n",
      "INFO:kafka.consumer.subscription_state:Updating subscribed topics to: ['Test22']\n",
      "INFO:kafka.cluster:Group coordinator for my-group1 is BrokerMetadata(nodeId='coordinator-0', host='localhost', port=9092, rack=None)\n",
      "INFO:kafka.coordinator:Discovered coordinator coordinator-0 for group my-group1\n",
      "INFO:kafka.coordinator:Starting new heartbeat thread\n",
      "INFO:kafka.coordinator.consumer:Revoking previously assigned partitions set() for group my-group1\n",
      "INFO:kafka.conn:<BrokerConnection node_id=coordinator-0 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]>: connecting to localhost:9092 [('127.0.0.1', 9092) IPv4]\n",
      "INFO:kafka.conn:<BrokerConnection node_id=coordinator-0 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]>: Connection complete.\n",
      "INFO:kafka.conn:<BrokerConnection node_id=bootstrap-0 host=localhost:9092 <connected> [IPv4 ('127.0.0.1', 9092)]>: Closing connection. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic is:  Test22\n",
      "Group is:  my-group1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:kafka.coordinator:(Re-)joining group my-group1\n",
      "INFO:kafka.coordinator:Successfully joined group my-group1 with generation 45\n",
      "INFO:kafka.consumer.subscription_state:Updated partition assignment: [TopicPartition(topic='Test22', partition=0)]\n",
      "INFO:kafka.coordinator.consumer:Setting newly assigned partitions {TopicPartition(topic='Test22', partition=0)} for group my-group1\n",
      "INFO:kafka.conn:<BrokerConnection node_id=0 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]>: connecting to localhost:9092 [('127.0.0.1', 9092) IPv4]\n",
      "INFO:kafka.conn:<BrokerConnection node_id=0 host=localhost:9092 <connecting> [IPv4 ('127.0.0.1', 9092)]>: Connection complete.\n"
     ]
    }
   ],
   "source": [
    "main('localhost:9092', 'Test22')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc17b8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
